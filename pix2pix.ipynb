{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nqzRNA7N1WnP"
      },
      "outputs": [],
      "source": [
        "!pip install fastai\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import glob\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.notebook import tqdm\n",
        "from PIL import Image\n",
        "from typing import List, Dict, Optional, Tuple, Any, Iterable\n",
        "from pathlib import Path\n",
        "\n",
        "from PIL import Image, ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import make_grid\n",
        "from torchvision.transforms import InterpolationMode\n",
        "import torchvision.models as models\n",
        "from fastai.vision.learner import create_body\n",
        "from fastai.data.external import untar_data, URLs\n",
        "from fastai.vision.models.unet import DynamicUnet\n",
        "from skimage.color import rgb2lab, lab2rgb\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "coco_root = untar_data(URLs.COCO_SAMPLE)\n",
        "coco_path = Path(coco_root) / \"train_sample\"\n",
        "assert coco_path.exists(), f\"Ne postoji putanja: {coco_path}\"\n",
        "\n",
        "paths = sorted(\n",
        "    glob.glob(str(coco_path / \"*.jpg\")) +\n",
        "    glob.glob(str(coco_path / \"*.jpeg\")) +\n",
        "    glob.glob(str(coco_path / \"*.png\"))\n",
        ")\n",
        "\n",
        "def is_ok(p):\n",
        "    try:\n",
        "        Image.open(p).verify()\n",
        "        return True\n",
        "    except:\n",
        "        return False\n",
        "\n",
        "paths = [p for p in paths if is_ok(p)]\n",
        "print(f\"Ukupno validnih slika: {len(paths)}\")\n",
        "\n",
        "np.random.seed(268)\n",
        "N_TARGET = 6_000\n",
        "N_TOTAL  = min(N_TARGET, len(paths))\n",
        "subset   = np.random.choice(paths, N_TOTAL, replace=False)\n",
        "\n",
        "perm = np.random.permutation(N_TOTAL)\n",
        "n_train = min(5_000, N_TOTAL)\n",
        "n_val   = max(0, N_TOTAL - n_train)\n",
        "\n",
        "train_idx = perm[:n_train]\n",
        "val_idx   = perm[n_train:n_train + n_val]\n",
        "\n",
        "train_paths = [subset[i] for i in train_idx]\n",
        "val_paths   = [subset[i] for i in val_idx]\n",
        "\n",
        "print(f\"Train: {len(train_paths)} | Val: {len(val_paths)}\")\n",
        "\n",
        "fig, axes = plt.subplots(4, 4, figsize=(10, 10))\n",
        "for ax, img_path in zip(axes.flatten(), train_paths[:16]):\n",
        "    ax.imshow(Image.open(img_path))\n",
        "    ax.axis(\"off\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "dGmQgvDnaGb6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ColorizationDataset(Dataset):\n",
        "    def __init__(self, img_paths, split=\"train\", size=256):\n",
        "        self.img_paths = [str(p) for p in img_paths]\n",
        "        self.split = split\n",
        "        self.size = int(size)\n",
        "\n",
        "        self._tx_train = transforms.Compose([\n",
        "            transforms.Resize((self.size, self.size), interpolation=Image.BICUBIC),\n",
        "            transforms.RandomHorizontalFlip(p=0.5),\n",
        "        ])\n",
        "        self._tx_eval = transforms.Resize((self.size, self.size), interpolation=Image.BICUBIC)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "\n",
        "    def _load_rgb(self, path):\n",
        "        img = Image.open(path).convert(\"RGB\")\n",
        "        return img\n",
        "\n",
        "    def _to_lab_tensor(self, pil_rgb):\n",
        "        np_rgb = np.array(pil_rgb)\n",
        "        lab = rgb2lab(np_rgb).astype(\"float32\")\n",
        "        tens = transforms.ToTensor()(lab)\n",
        "        L  = tens[[0], ...] / 50.0 - 1.0\n",
        "        ab = tens[[1, 2], ...] / 110.0\n",
        "        return L, ab\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path = self.img_paths[idx]\n",
        "        img = self._load_rgb(path)\n",
        "\n",
        "        if self.split == \"train\":\n",
        "            img = self._tx_train(img)\n",
        "        else:\n",
        "            img = self._tx_eval(img)\n",
        "\n",
        "        L, ab = self._to_lab_tensor(img)\n",
        "        return {\"L\": L, \"ab\": ab}\n",
        "\n",
        "\n",
        "def make_dataloaders(*, paths, split=\"train\", batch_size=16, num_workers=4, pin_memory=True, size=256):\n",
        "    ds = ColorizationDataset(img_paths=paths, split=split, size=size)\n",
        "    return DataLoader(ds, batch_size=batch_size, num_workers=num_workers, pin_memory=pin_memory)"
      ],
      "metadata": {
        "id": "R4cBc7xjaIYp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dl = make_dataloaders(paths=train_paths, split=\"train\")\n",
        "val_dl   = make_dataloaders(paths=val_paths,   split=\"val\")\n",
        "\n",
        "batch = next(iter(train_dl))\n",
        "L_batch, ab_batch = batch[\"L\"], batch[\"ab\"]\n",
        "\n",
        "print(f\"L shape:  {L_batch.shape} | ab shape: {ab_batch.shape}\")\n",
        "print(f\"Num train batches: {len(train_dl)} | Num val batches: {len(val_dl)}\")\n",
        "\n",
        "n_show = 4\n",
        "plt.figure(figsize=(12, 3*n_show))\n",
        "\n",
        "for i in range(n_show):\n",
        "    L = L_batch[i].numpy()[0]\n",
        "    ab = ab_batch[i].numpy().transpose(1,2,0)\n",
        "\n",
        "    L_img = (L + 1.) * 50.0\n",
        "    ab_img = ab * 110.\n",
        "\n",
        "    lab_img = np.concatenate((L_img[...,None], ab_img), axis=2)\n",
        "    rgb_img = lab2rgb(lab_img.astype(\"float32\"))\n",
        "\n",
        "    gray_img = lab2rgb(np.concatenate((L_img[...,None], np.zeros_like(ab_img)), axis=2))\n",
        "\n",
        "    plt.subplot(n_show, 2, 2*i+1)\n",
        "    plt.imshow(gray_img)\n",
        "    plt.title(\"Input (L channel)\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.subplot(n_show, 2, 2*i+2)\n",
        "    plt.imshow(rgb_img)\n",
        "    plt.title(\"Ground Truth (L+ab)\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZlHU9qccaJZ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UnetBlock(nn.Module):\n",
        "    def __init__(self, nf, ni, submodule=None, input_c=None, dropout=False,\n",
        "                 innermost=False, outermost=False):\n",
        "        super().__init__()\n",
        "        self.outermost = outermost\n",
        "\n",
        "        if input_c is None:\n",
        "            input_c = nf\n",
        "\n",
        "        downrelu = nn.LeakyReLU(0.2, True)\n",
        "        downnorm = nn.InstanceNorm2d(ni)\n",
        "        uprelu   = nn.ReLU(True)\n",
        "        upnorm = nn.InstanceNorm2d(nf)\n",
        "\n",
        "        downconv = nn.Conv2d(input_c, ni, kernel_size=4, stride=2, padding=1, bias=False)\n",
        "\n",
        "        if outermost:\n",
        "            upconv = nn.ConvTranspose2d(ni * 2, nf, kernel_size=4, stride=2, padding=1)\n",
        "\n",
        "            down = [downconv]\n",
        "            up = [uprelu, upconv, nn.Tanh()]\n",
        "            model = down + [submodule] + up\n",
        "\n",
        "        elif innermost:\n",
        "            upconv = nn.ConvTranspose2d(ni, nf, kernel_size=4, stride=2, padding=1, bias=False)\n",
        "\n",
        "            down = [downrelu, downconv]\n",
        "            up = [uprelu, upconv, upnorm]\n",
        "            model = down + up\n",
        "\n",
        "        else:\n",
        "            upconv = nn.ConvTranspose2d(ni * 2, nf, kernel_size=4, stride=2, padding=1, bias=False)\n",
        "\n",
        "            down = [downrelu, downconv, downnorm]\n",
        "            up = [uprelu, upconv, upnorm]\n",
        "\n",
        "            if dropout:\n",
        "                up.append(nn.Dropout(0.5))\n",
        "            model = down + [submodule] + up\n",
        "\n",
        "        self.model = nn.Sequential(*model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.outermost:\n",
        "            return self.model(x)\n",
        "        else:\n",
        "            return torch.cat([x, self.model(x)], dim=1)\n",
        "\n",
        "\n",
        "class Unet(nn.Module):\n",
        "    def __init__(self, input_c=1, output_c=2, n_down=8, num_filters=64):\n",
        "        super().__init__()\n",
        "\n",
        "        unet_block = UnetBlock(num_filters * 8, num_filters * 8, innermost=True)\n",
        "\n",
        "        for _ in range(n_down - 5):\n",
        "            unet_block = UnetBlock(num_filters * 8, num_filters * 8, submodule=unet_block, dropout=True)\n",
        "\n",
        "        out_filters = num_filters * 8\n",
        "        for _ in range(3):\n",
        "            unet_block = UnetBlock(out_filters // 2, out_filters, submodule=unet_block)\n",
        "            out_filters //= 2\n",
        "\n",
        "        self.model = UnetBlock(output_c, out_filters, input_c=input_c,\n",
        "                               submodule=unet_block, outermost=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n"
      ],
      "metadata": {
        "id": "znvGgX97dPA8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PatchDiscriminator(nn.Module):\n",
        "    def __init__(self, input_c: int, num_filters: int = 64, n_down: int = 3) -> None:\n",
        "        super().__init__()\n",
        "        layers: List[nn.Module] = []\n",
        "\n",
        "        layers.append(self._block(in_ch=input_c, out_ch=num_filters, k=4, s=2, p=1,\n",
        "                                  use_norm=False, use_act=True))\n",
        "\n",
        "        for i in range(n_down):\n",
        "            in_ch  = num_filters * (2 ** i)\n",
        "            out_ch = num_filters * (2 ** (i + 1))\n",
        "            stride = 1 if i == (n_down - 1) else 2\n",
        "            layers.append(self._block(in_ch=in_ch, out_ch=out_ch, k=4, s=stride, p=1,\n",
        "                                      use_norm=True, use_act=True))\n",
        "\n",
        "        layers.append(self._block(in_ch=num_filters * (2 ** n_down), out_ch=1, k=4, s=1, p=1,\n",
        "                                  use_norm=False, use_act=False))\n",
        "\n",
        "        self.model = nn.Sequential(*layers)\n",
        "\n",
        "    @staticmethod\n",
        "    def _block(in_ch: int, out_ch: int, k: int = 4, s: int = 2, p: int = 1,\n",
        "               use_norm: bool = True, use_act: bool = True) -> nn.Sequential:\n",
        "\n",
        "        layers: List[nn.Module] = []\n",
        "        layers.append(nn.Conv2d(in_channels=in_ch,\n",
        "                                out_channels=out_ch,\n",
        "                                kernel_size=k,\n",
        "                                stride=s,\n",
        "                                padding=p,\n",
        "                                bias=not use_norm))\n",
        "        if use_norm:\n",
        "            layers.append(nn.BatchNorm2d(out_ch))\n",
        "        if use_act:\n",
        "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        return self.model(x)\n"
      ],
      "metadata": {
        "id": "taziZPGshxZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GANLoss(nn.Module):\n",
        "    def __init__(self, gan_mode='vanilla', real_label=1.0, fake_label=0.0):\n",
        "        super().__init__()\n",
        "        self.register_buffer('real_label', torch.tensor(real_label))\n",
        "        self.register_buffer('fake_label', torch.tensor(fake_label))\n",
        "\n",
        "        if gan_mode == 'vanilla':\n",
        "            self.loss = nn.BCEWithLogitsLoss()\n",
        "        elif gan_mode == 'lsgan':\n",
        "            self.loss = nn.MSELoss()\n",
        "        else:\n",
        "            raise NotImplementedError(f\"gan_mode '{gan_mode}' not implemented\")\n",
        "\n",
        "    def get_labels(self, preds, target_is_real):\n",
        "        labels = self.real_label if target_is_real else self.fake_label\n",
        "        return labels.expand_as(preds)\n",
        "\n",
        "    def forward(self, preds, target_is_real):\n",
        "        labels = self.get_labels(preds, target_is_real)\n",
        "        return self.loss(preds, labels)\n"
      ],
      "metadata": {
        "id": "YSoCmT7djWNZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def init_weights(net, init_type=\"normal\", gain=0.02):\n",
        "\n",
        "    def init_func(m):\n",
        "        classname = m.__class__.__name__\n",
        "\n",
        "        if hasattr(m, \"weight\") and \"Conv\" in classname:\n",
        "            if init_type == \"normal\":\n",
        "                nn.init.normal_(m.weight.data, mean=0.0, std=gain)\n",
        "            elif init_type == \"xavier\":\n",
        "                nn.init.xavier_normal_(m.weight.data, gain=gain)\n",
        "            elif init_type == \"kaiming\":\n",
        "                nn.init.kaiming_normal_(m.weight.data, a=0, mode=\"fan_in\")\n",
        "            else:\n",
        "                raise ValueError(f\"Nepoznata inicijalizacija: {init_type}\")\n",
        "\n",
        "            if m.bias is not None:\n",
        "                nn.init.constant_(m.bias.data, 0.0)\n",
        "\n",
        "        elif \"BatchNorm2d\" in classname:\n",
        "            nn.init.normal_(m.weight.data, mean=1.0, std=gain)\n",
        "            nn.init.constant_(m.bias.data, 0.0)\n",
        "\n",
        "    net.apply(init_func)\n",
        "    print(f\"Model inicijalizovan ({init_type} inicijalizacija)\")\n",
        "    return net\n",
        "\n",
        "\n",
        "def init_model(model, device, init_type=\"normal\", gain=0.02):\n",
        "    model = model.to(device)\n",
        "    return init_weights(model, init_type=init_type, gain=gain)\n"
      ],
      "metadata": {
        "id": "cB02AlCEj-6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ColorizationModel(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        net_G: Optional[nn.Module] = None,\n",
        "        lr_G: float = 2e-4,\n",
        "        lr_D: float = 2e-4,\n",
        "        beta1: float = 0.5,\n",
        "        beta2: float = 0.999,\n",
        "        lambda_L1: float = 100.0,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.lambda_L1 = float(lambda_L1)\n",
        "\n",
        "        self.net_G = (net_G if net_G is not None\n",
        "                      else Unet(input_c=1, output_c=2, n_down=8, num_filters=64))\n",
        "        self.net_G = init_model(self.net_G, self.device)\n",
        "\n",
        "        self.net_D = init_model(PatchDiscriminator(input_c=3, n_down=3, num_filters=64), self.device)\n",
        "\n",
        "        self.adv_criterion = GANLoss(gan_mode=\"vanilla\").to(self.device)\n",
        "        self.l1_criterion  = nn.L1Loss()\n",
        "\n",
        "        self.opt_G = optim.Adam(self.net_G.parameters(), lr=lr_G, betas=(beta1, beta2))\n",
        "        self.opt_D = optim.Adam(self.net_D.parameters(), lr=lr_D, betas=(beta1, beta2))\n",
        "\n",
        "        self.L: torch.Tensor  = torch.empty(0)\n",
        "        self.ab: torch.Tensor = torch.empty(0)\n",
        "        self.fake_color: torch.Tensor = torch.empty(0)\n",
        "\n",
        "        self.loss_D_fake = torch.tensor(0.0)\n",
        "        self.loss_D_real = torch.tensor(0.0)\n",
        "        self.loss_D      = torch.tensor(0.0)\n",
        "        self.loss_G_GAN  = torch.tensor(0.0)\n",
        "        self.loss_G_L1   = torch.tensor(0.0)\n",
        "        self.loss_G      = torch.tensor(0.0)\n",
        "\n",
        "    @staticmethod\n",
        "    def _cat_L_ab(L: torch.Tensor, ab: torch.Tensor) -> torch.Tensor:\n",
        "        return torch.cat([L, ab], dim=1)\n",
        "\n",
        "    @staticmethod\n",
        "    def _toggle_grad(model: nn.Module, requires_grad: bool) -> None:\n",
        "        for p in model.parameters():\n",
        "            p.requires_grad = requires_grad\n",
        "\n",
        "    def setup_input(self, batch: Dict[str, torch.Tensor]) -> None:\n",
        "        self.L  = batch[\"L\"].to(self.device, non_blocking=True)\n",
        "        self.ab = batch[\"ab\"].to(self.device, non_blocking=True)\n",
        "\n",
        "    def forward(self) -> None:\n",
        "        self.fake_color = self.net_G(self.L)\n",
        "\n",
        "    def backward_D(self) -> None:\n",
        "        fake_pair = self._cat_L_ab(self.L, self.fake_color).detach()\n",
        "        pred_fake = self.net_D(fake_pair)\n",
        "        self.loss_D_fake = self.adv_criterion(pred_fake, target_is_real=False)\n",
        "\n",
        "        real_pair = self._cat_L_ab(self.L, self.ab)\n",
        "        pred_real = self.net_D(real_pair)\n",
        "        self.loss_D_real = self.adv_criterion(pred_real, target_is_real=True)\n",
        "\n",
        "        self.loss_D = 0.5 * (self.loss_D_fake + self.loss_D_real)\n",
        "        self.loss_D.backward()\n",
        "\n",
        "    def backward_G(self) -> None:\n",
        "        fake_pair = self._cat_L_ab(self.L, self.fake_color)\n",
        "        pred_fake = self.net_D(fake_pair)\n",
        "\n",
        "        self.loss_G_GAN = self.adv_criterion(pred_fake, target_is_real=True)\n",
        "        self.loss_G_L1  = self.l1_criterion(self.fake_color, self.ab) * self.lambda_L1\n",
        "        self.loss_G     = self.loss_G_GAN + self.loss_G_L1\n",
        "        self.loss_G.backward()\n",
        "\n",
        "    def optimize(self) -> None:\n",
        "        self.forward()\n",
        "\n",
        "        self._toggle_grad(self.net_D, True)\n",
        "        self.opt_D.zero_grad(set_to_none=True)\n",
        "        self.backward_D()\n",
        "        self.opt_D.step()\n",
        "\n",
        "        self._toggle_grad(self.net_D, False)\n",
        "        self.opt_G.zero_grad(set_to_none=True)\n",
        "        self.backward_G()\n",
        "        self.opt_G.step()\n"
      ],
      "metadata": {
        "id": "fR5IjOSskqmI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AverageMeter:\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.count = 0\n",
        "        self.sum   = 0.0\n",
        "        self.avg   = 0.0\n",
        "\n",
        "    def update(self, val: float, count: int = 1):\n",
        "        self.count += count\n",
        "        self.sum   += val * count\n",
        "        self.avg    = self.sum / max(self.count, 1)\n",
        "\n",
        "\n",
        "def create_loss_meters() -> Dict[str, AverageMeter]:\n",
        "    names = [\"loss_D_fake\", \"loss_D_real\", \"loss_D\",\n",
        "             \"loss_G_GAN\", \"loss_G_L1\", \"loss_G\"]\n",
        "    return {n: AverageMeter() for n in names}\n",
        "\n",
        "\n",
        "def update_losses(model: nn.Module, meters: Dict[str, AverageMeter], count: int) -> None:\n",
        "    for name, meter in meters.items():\n",
        "        meter.update(getattr(model, name).item(), count=count)\n",
        "\n",
        "\n",
        "def log_results(meters: Dict[str, AverageMeter]) -> None:\n",
        "    for name, meter in meters.items():\n",
        "        print(f\"{name}: {meter.avg:.5f}\")\n",
        "\n",
        "def _lab_tensors_to_rgb_uint8(\n",
        "    L: torch.Tensor, ab: torch.Tensor\n",
        ") -> np.ndarray:\n",
        "\n",
        "    L_real  = (L + 1.0) * 50.0\n",
        "    ab_real = ab * 110.0\n",
        "\n",
        "    Lab = torch.cat([L_real, ab_real], dim=1).permute(0, 2, 3, 1).detach().cpu().numpy()\n",
        "\n",
        "    rgb_list = []\n",
        "    for i in range(Lab.shape[0]):\n",
        "        rgb_f = lab2rgb(Lab[i])\n",
        "        rgb_u8 = (np.clip(rgb_f, 0, 1) * 255).astype(np.uint8)\n",
        "        rgb_list.append(rgb_u8)\n",
        "    return np.stack(rgb_list, axis=0)\n",
        "\n",
        "\n",
        "def _gray_from_L_uint8(L: torch.Tensor) -> np.ndarray:\n",
        "    L_real = (L + 1.0) * 50.0   # [0..100]\n",
        "\n",
        "    B, _, H, W = L.shape\n",
        "    zeros = torch.zeros((B, 2, H, W), device=L.device, dtype=L.dtype)\n",
        "    gray_rgb = _lab_tensors_to_rgb_uint8(L, zeros)\n",
        "    return gray_rgb\n",
        "\n",
        "def _build_triptychs_from_batch(\n",
        "    L: torch.Tensor, fake_ab: torch.Tensor, real_ab: torch.Tensor\n",
        ") -> List[Tuple[np.ndarray, np.ndarray, np.ndarray, str]]:\n",
        "\n",
        "    gt_rgb   = _lab_tensors_to_rgb_uint8(L, real_ab)\n",
        "    gray_rgb = _gray_from_L_uint8(L)\n",
        "    pred_rgb = _lab_tensors_to_rgb_uint8(L, fake_ab)\n",
        "\n",
        "    triptychs = []\n",
        "    B = L.shape[0]\n",
        "    for i in range(B):\n",
        "        stem = f\"sample_{i:03d}\"\n",
        "        triptychs.append((gt_rgb[i], gray_rgb[i], pred_rgb[i], stem))\n",
        "    return triptychs\n",
        "\n",
        "def plot_triptych_grid(triptychs: list[tuple[np.ndarray, np.ndarray, np.ndarray, str]]) -> None:\n",
        "    n = len(triptychs)\n",
        "    fig, axes = plt.subplots(n, 3, figsize=(12, 4 * n))\n",
        "\n",
        "    if n == 1:\n",
        "        axes = [axes]\n",
        "\n",
        "    for ax_row, (orig, gray, color, _) in zip(axes, triptychs):\n",
        "        for ax, img, title in zip(ax_row, [orig, gray, color], [\"Original\", \"Grayscale\", \"Colorized (pix2pix)\"]):\n",
        "            ax.imshow(img)\n",
        "            ax.set_title(title)\n",
        "            ax.axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def save_triptychs(triptychs: list[tuple[np.ndarray, np.ndarray, np.ndarray, str]], out_dir: Path) -> None:\n",
        "    out_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    for orig, gray, color, stem in triptychs:\n",
        "        fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
        "        for ax, img, title in zip(axes, [orig, gray, color], [\"Original\", \"Grayscale\", \"Colorized (pix2pix)\"]):\n",
        "            ax.imshow(img)\n",
        "            ax.set_title(title)\n",
        "            ax.axis(\"off\")\n",
        "\n",
        "        fig.tight_layout()\n",
        "        fig.savefig(out_dir / f\"{stem}_triptych.png\", dpi=150)\n",
        "        plt.close(fig)\n",
        "\n",
        "\n",
        "def visualize_batch(\n",
        "    model: nn.Module,\n",
        "    data: dict,\n",
        "    *,\n",
        "    save: bool = False,\n",
        "    out_dir: Path = Path(\"./colorization_viz\"),\n",
        "    max_show: int = 5\n",
        ") -> None:\n",
        "\n",
        "    model.net_G.eval()\n",
        "    with torch.no_grad():\n",
        "        model.setup_input(data)\n",
        "        model.forward()\n",
        "        L   = model.L\n",
        "        ab  = model.ab\n",
        "        fab = model.fake_color\n",
        "\n",
        "    all_triptychs = _build_triptychs_from_batch(L, fab, ab)[:max_show]\n",
        "\n",
        "    plot_triptych_grid(all_triptychs)\n",
        "    if save:\n",
        "        save_triptychs(all_triptychs, out_dir)"
      ],
      "metadata": {
        "id": "9mSvGJW2ml5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(\n",
        "    model: nn.Module,\n",
        "    train_dl,\n",
        "    epochs: int,\n",
        "    val_dl=None,\n",
        "    display_every: int = 100,\n",
        "    viz_save: bool = False\n",
        "):\n",
        "    viz_batch = next(iter(val_dl)) if val_dl is not None else None\n",
        "\n",
        "    for e in range(1, epochs + 1):\n",
        "        meters = create_loss_meters()\n",
        "        for i, data in enumerate(tqdm(train_dl, desc=f\"Epoch {e}/{epochs}\"), start=1):\n",
        "            model.setup_input(data)\n",
        "            model.optimize()\n",
        "\n",
        "            bsize = data[\"L\"].size(0)\n",
        "            update_losses(model, meters, count=bsize)\n",
        "\n",
        "            if i % display_every == 0:\n",
        "                print(f\"\\n[Epoch {e}/{epochs}] Iter {i}/{len(train_dl)}\")\n",
        "                log_results(meters)\n",
        "\n",
        "                if viz_batch is not None:\n",
        "                    visualize_batch(model, viz_batch, save=viz_save)\n",
        "                else:\n",
        "                    visualize_batch(model, data, save=viz_save)\n",
        "\n",
        "        print(f\"\\n===> Epoch {e} done.\")\n",
        "        log_results(meters)\n",
        "        if viz_batch is not None:\n",
        "            visualize_batch(model, viz_batch, save=viz_save)\n",
        "\n",
        "model = ColorizationModel()\n",
        "train_model(model, train_dl, epochs=30, val_dl=val_dl, display_every=100, viz_save=True)"
      ],
      "metadata": {
        "id": "WunVEuu8aTzK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_resnet_18(n_input: int = 1, n_output: int = 2, size: int = 256) -> nn.Module:\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    resnet18_model = models.resnet18(pretrained=True)\n",
        "    body = create_body(resnet18_model, n_in=n_input, cut=-2)\n",
        "\n",
        "    net_G = DynamicUnet(body, n_output, (size, size)).to(device)\n",
        "    return net_G\n",
        "\n",
        "\n",
        "@torch.inference_mode()\n",
        "def _valid_step_L1(\n",
        "    net_G: nn.Module,\n",
        "    val_dl: Iterable[Dict[str, Any]],\n",
        "    criterion: nn.Module,\n",
        "    device: torch.device\n",
        ") -> float:\n",
        "    prev_mode = net_G.training\n",
        "    net_G.eval()\n",
        "\n",
        "    total_loss = 0.0\n",
        "    total_count = 0\n",
        "\n",
        "    for batch in val_dl:\n",
        "        L = batch[\"L\"].to(device, non_blocking=True)\n",
        "        ab = batch[\"ab\"].to(device, non_blocking=True)\n",
        "\n",
        "        pred = net_G(L)\n",
        "        loss = criterion(pred, ab).item()\n",
        "\n",
        "        batch_size = L.size(0)\n",
        "        total_loss += loss * batch_size\n",
        "        total_count += batch_size\n",
        "\n",
        "    net_G.train(prev_mode)\n",
        "\n",
        "    if total_count == 0:\n",
        "        return 0.0\n",
        "    return total_loss / total_count\n"
      ],
      "metadata": {
        "id": "wkKIlnXCNm6A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pretrain_generator(\n",
        "    net_G: nn.Module,\n",
        "    train_dl: Iterable[Dict[str, Any]],\n",
        "    val_dl:   Iterable[Dict[str, Any]],\n",
        "    opt: torch.optim.Optimizer,\n",
        "    criterion: nn.Module,\n",
        "    epochs: int,\n",
        "    device: torch.device,\n",
        "    *,\n",
        "    use_amp: bool = True,\n",
        "    grad_clip: Optional[float] = None\n",
        ") -> List[Dict[str, float]]:\n",
        "\n",
        "    history: List[Dict[str, float]] = []\n",
        "    scaler = GradScaler(enabled=use_amp)\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        net_G.train()\n",
        "        epoch_loss, seen = 0.0, 0\n",
        "        t0 = time.time()\n",
        "\n",
        "        pbar = tqdm(train_dl, desc=f\"[Pretrain G] Epoch {epoch}/{epochs}\", leave=False)\n",
        "        for batch in pbar:\n",
        "            L  = batch[\"L\"].to(device, non_blocking=True)\n",
        "            ab = batch[\"ab\"].to(device, non_blocking=True)\n",
        "\n",
        "            opt.zero_grad(set_to_none=True)\n",
        "            with autocast(enabled=use_amp):\n",
        "                pred  = net_G(L)\n",
        "                loss  = criterion(pred, ab)\n",
        "\n",
        "            if use_amp:\n",
        "                scaler.scale(loss).backward()\n",
        "                if grad_clip is not None:\n",
        "                    scaler.unscale_(opt)\n",
        "                    torch.nn.utils.clip_grad_norm_(net_G.parameters(), grad_clip)\n",
        "                scaler.step(opt)\n",
        "                scaler.update()\n",
        "            else:\n",
        "                loss.backward()\n",
        "                if grad_clip is not None:\n",
        "                    torch.nn.utils.clip_grad_norm_(net_G.parameters(), grad_clip)\n",
        "                opt.step()\n",
        "\n",
        "            bsz = L.size(0)\n",
        "            epoch_loss += loss.item() * bsz\n",
        "            seen       += bsz\n",
        "            pbar.set_postfix(loss=f\"{epoch_loss/seen:.4f}\")\n",
        "\n",
        "        train_loss = epoch_loss / max(1, seen)\n",
        "        val_loss   = _valid_step_L1(net_G, val_dl, criterion, device)\n",
        "        dt = time.time() - t0\n",
        "\n",
        "        print(f\"Epoch {epoch:03d}/{epochs} | L1(train) {train_loss:.5f} | \"\n",
        "              f\"L1(val) {val_loss:.5f} | {dt:.1f}s\")\n",
        "\n",
        "        history.append({\"epoch\": epoch, \"train_l1\": train_loss, \"val_l1\": val_loss})\n",
        "\n",
        "    return history\n"
      ],
      "metadata": {
        "id": "jxHS4-gFPNwq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net_G = build_resnet_18(n_input=1, n_output=2, size=256)\n",
        "opt_G = optim.Adam(net_G.parameters(), lr=1e-4)\n",
        "crit  = nn.L1Loss()\n",
        "\n",
        "pretrain_generator(net_G, train_dl, val_dl, opt_G, crit, epochs=1, device=device)\n",
        "\n",
        "torch.save(net_G.state_dict(), \"resnet-18.pt\")"
      ],
      "metadata": {
        "id": "qQtCGdUkPuH7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net_G = build_resnet_18(n_input=1, n_output=2, size=256)\n",
        "net_G.load_state_dict(torch.load(\"resnet-18.pt\", map_location=device))\n",
        "\n",
        "model = ColorizationModel(net_G=net_G)\n",
        "train_model(model, train_dl, epochs=30, val_dl=val_dl, display_every=100, viz_save=True)"
      ],
      "metadata": {
        "id": "zhIqVEPqP3Aa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}